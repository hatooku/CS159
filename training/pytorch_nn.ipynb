{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset\n",
    "from tensorboardX import SummaryWriter\n",
    "import time\n",
    "\n",
    "from preprocess_pytorch import fetch_data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"15000_pytorch_1v0_partialstate\"\n",
    "SAVE_EVERY = 10 # Save every N epochs\n",
    "\n",
    "INPUT_SIZE = 59\n",
    "\n",
    "NUM_EPOCHS = 30\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.0005"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = fetch_data(['data/15000_partialstate_1v0.log'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.0, random_state=42)\n",
    "y_train_actions, y_train_parameters = y_train[:,0].astype(np.long), y_train[:,1:]\n",
    "y_test_actions, y_test_parameters = y_test[:,0].astype(np.long), y_test[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_data = X_train.shape[0]\n",
    "num_test_data = X_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "train_dataset = TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train_actions), torch.from_numpy(y_train_parameters))\n",
    "test_dataset = TensorDataset(torch.from_numpy(X_test), torch.from_numpy(y_test_actions), torch.from_numpy(y_test_parameters))\n",
    "\n",
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=BATCH_SIZE, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=BATCH_SIZE, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DASH TURN TACKLE KICK 2 1 1 2\n",
    "\n",
    "# Fully connected neural network with one hidden layer\n",
    "from pytorch_model import NeuralNet\n",
    "    \n",
    "def get_test_loss(model, criterion_actions, criterion_parameters, test_loader, num_test_data):\n",
    "    return 0, 0 # TODO REMOVE\n",
    "    test_loss_actions = 0\n",
    "    test_loss_parameters = 0\n",
    "    with torch.no_grad():\n",
    "        for X, y_actions, y_parameters in test_loader:\n",
    "            X = X.to(device)\n",
    "            y_actions = y_actions.to(device)\n",
    "            y_parameters = y_parameters.to(device)\n",
    "            outputs_actions, output_parameters = model(X)\n",
    "            loss_actions = criterion_actions(outputs_actions, y_actions)            \n",
    "            relevance_map = y_parameters != y_parameters\n",
    "            y_parameters[relevance_map] = 0\n",
    "            output_parameters[relevance_map] = 0\n",
    "            \n",
    "            loss_parameters = criterion_parameters(output_parameters, y_parameters) / 2 / 400\n",
    "            \n",
    "            test_loss_actions += loss_actions.item()\n",
    "            test_loss_parameters += loss_parameters.item()\n",
    "    return test_loss_actions / num_test_data, test_loss_parameters / num_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNet(INPUT_SIZE).to(device).double()\n",
    "# Loss and optimizer\n",
    "criterion_actions = nn.CrossEntropyLoss(size_average=False)\n",
    "criterion_parameters = nn.MSELoss(size_average=False) # MSE Sum\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)  \n",
    "\n",
    "writer = SummaryWriter() # Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "time.sleep(5)\n",
    "x = time.time() - start_time # seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "total_step = len(train_loader)\n",
    "update_interval = total_step // 3\n",
    "start_time = time.time()\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    train_loss_actions = 0\n",
    "    train_loss_parameters = 0\n",
    "    for i, (X, y_actions, y_parameters) in enumerate(train_loader):  \n",
    "        # Move tensors to the configured device\n",
    "        X = X.to(device)\n",
    "        y_actions = y_actions.to(device)\n",
    "        y_parameters = y_parameters.to(device)\n",
    "        \n",
    "        N = X.shape[0] # num of data\n",
    "        \n",
    "        # Forward pass\n",
    "        output_actions, output_parameters = model(X)\n",
    "        loss_actions = criterion_actions(output_actions, y_actions)\n",
    "        \n",
    "        # Figure out relevance using nans\n",
    "        relevance_map = y_parameters != y_parameters\n",
    "        y_parameters[relevance_map] = 0\n",
    "        output_parameters[relevance_map] = 0\n",
    "        \n",
    "        loss_parameters = criterion_parameters(output_parameters, y_parameters) / 2 / 400\n",
    "        loss = (loss_actions + loss_parameters) / N\n",
    "        \n",
    "        train_loss_actions += loss_actions\n",
    "        train_loss_parameters += loss_parameters\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i + 1) % update_interval == 0:\n",
    "            print('Epoch [{}/{}], Iteration [{}/{}], Time Elapsed: {:.4f} s'.format(\n",
    "                epoch+1, NUM_EPOCHS, i + 1, total_step, time.time() - start_time))\n",
    "        \n",
    "    train_loss_actions /= num_train_data\n",
    "    train_loss_parameters /= num_train_data\n",
    "    train_loss_total = train_loss_actions + train_loss_parameters\n",
    "    \n",
    "    test_loss_actions, test_loss_parameters = get_test_loss(\n",
    "        model, criterion_actions, criterion_parameters, test_loader, num_test_data)\n",
    "    test_loss_total = test_loss_actions + test_loss_parameters\n",
    "    \n",
    "    writer.add_scalar('total_loss/1:training_loss', train_loss_total, epoch + 1)\n",
    "    writer.add_scalar('total_loss/2:test_loss', test_loss_total, epoch + 1)\n",
    "    \n",
    "    writer.add_scalar('action_loss/1:training_loss', train_loss_actions, epoch + 1)\n",
    "    writer.add_scalar('action_loss/2:test_loss', test_loss_actions, epoch + 1)\n",
    "    \n",
    "    writer.add_scalar('parameters_loss/1:training_loss', train_loss_parameters, epoch + 1)\n",
    "    writer.add_scalar('parameters_loss/2:test_loss', test_loss_parameters, epoch + 1)\n",
    "    \n",
    "    if (epoch + 1) % SAVE_EVERY == 0:\n",
    "        filename = './models/%s_%d.model' % (NAME, epoch)\n",
    "        torch.save(model.state_dict(), filename)\n",
    "        print(\"File %s created\" % filename)\n",
    "    \n",
    "    print('Epoch [{}/{}], Loss: {:.4f} ({:.4f} + {:.4f}), Test Loss: {:.4f} ({:.4f} + {:.4f})'.format(\n",
    "        epoch+1, NUM_EPOCHS, \n",
    "        train_loss_total, train_loss_actions, train_loss_parameters,\n",
    "        test_loss_total, test_loss_actions, test_loss_parameters))\n",
    "    print(\"Time Elapsed: {:.4f} mins\".format((time.time() - start_time) / 60.0))\n",
    "    \n",
    "filename = './models/%s_FINAL.model' % (NAME)\n",
    "torch.save(model.state_dict(), filename)\n",
    "print(\"File %s created\" % filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_p36]",
   "language": "python",
   "name": "conda-env-pytorch_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
