{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from preprocess import fetch_data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"PYTORCH_MODEL\"\n",
    "SAVE_EVERY = 10 # Save every N epochs\n",
    "\n",
    "\n",
    "INPUT_SIZE = 59\n",
    "NUM_EPOCHS = 30\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = fetch_data(['data/200_fullstate_1v0.log'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "y_train_actions, y_train_parameters = np.argmax(y_train[:,:4], axis=1), y_train[:,4:]\n",
    "y_test_actions, y_test_parameters = np.argmax(y_test[:,:4], axis=1), y_test[:,4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_data = X_train.shape[0]\n",
    "num_test_data = X_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "train_dataset = TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train_actions), torch.from_numpy(y_train_parameters))\n",
    "test_dataset = TensorDataset(torch.from_numpy(X_test), torch.from_numpy(y_test_actions), torch.from_numpy(y_test_parameters))\n",
    "\n",
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=BATCH_SIZE, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=BATCH_SIZE, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DASH TURN TACKLE KICK 2 1 1 2\n",
    "\n",
    "# Fully connected neural network with one hidden layer\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_features=INPUT_SIZE, out_features=1000) \n",
    "        self.relu1 = nn.LeakyReLU()\n",
    "        self.fc2 = nn.Linear(in_features=1000, out_features=512) \n",
    "        self.relu2 = nn.LeakyReLU()\n",
    "        self.fc3 = nn.Linear(in_features=512, out_features=200) \n",
    "        self.relu3 = nn.LeakyReLU()\n",
    "        self.fc4 = nn.Linear(in_features=200, out_features=64)\n",
    "        self.relu4 = nn.LeakyReLU()\n",
    "        self.output_actions = nn.Linear(in_features=64, out_features=4)\n",
    "        \n",
    "        self.output_parameters_dash = nn.Linear(in_features=64, out_features=2)\n",
    "        self.output_parameters_turn = nn.Linear(in_features=64, out_features=1)\n",
    "        self.output_parameters_tackle = nn.Linear(in_features=64, out_features=1)\n",
    "        self.output_parameters_kick = nn.Linear(in_features=64, out_features=2)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.fc3(out)\n",
    "        out = self.relu3(out)\n",
    "        out = self.fc4(out)\n",
    "        out = self.relu4(out)\n",
    "        \n",
    "        out_actions = self.output_actions(out)\n",
    "        \n",
    "        out_dash = self.output_parameters_dash(out)\n",
    "        out_turn = self.output_parameters_turn(out)\n",
    "        out_tackle = self.output_parameters_tackle(out)\n",
    "        out_kick = self.output_parameters_kick(out)\n",
    "        \n",
    "        return out_actions, [out_dash, out_turn, out_tackle, out_kick]\n",
    "    \n",
    "def get_test_loss(model, criterion_actions, criterion_parameters, test_loader):\n",
    "    loss = 0\n",
    "    with torch.no_grad():\n",
    "        for X, y_actions, y_parameters in test_loader:\n",
    "            X = X.to(device)\n",
    "            y_actions = y_actions.to(device)\n",
    "            y_parameters = y_parameters.to(device)\n",
    "            outputs_actions, output_parameters_array = model(X)\n",
    "            loss_actions = criterion_actions(outputs_actions, y_actions)\n",
    "            \n",
    "            y_parameters = split_parameters(y_parameters)\n",
    "            loss_parameters = compute_parameter_loss(output_parameters_array, y_parameters, y_actions, criterion_parameters, p=True) / (2 * N)\n",
    "            loss = loss_actions + loss_parameters\n",
    "    return loss.item()        \n",
    "\n",
    "def compute_parameter_loss(output_parameters_array, y_parameters, y_actions, criterion, p=False):\n",
    "    N = y_actions.shape[0]\n",
    "    for i in range(N):\n",
    "        chosen_action = y_actions[i].item()\n",
    "        relevant_output_parameters = output_parameters_array[chosen_action][i]\n",
    "        relevant_y_parameters = y_parameters[chosen_action][i]\n",
    "        if i == 0:\n",
    "            loss = criterion(relevant_output_parameters, relevant_y_parameters)\n",
    "        else:\n",
    "            loss += criterion(relevant_output_parameters, relevant_y_parameters)\n",
    "    return loss\n",
    "\n",
    "def split_parameters(parameters):\n",
    "    return parameters[:,:2], parameters[:, 2:3], parameters[:, 3:4], parameters[:, 4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNet().to(device).double()\n",
    "# Loss and optimizer\n",
    "criterion_actions = nn.CrossEntropyLoss()\n",
    "criterion_parameters = nn.MSELoss(size_average=False) # MSE Sum\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)  \n",
    "\n",
    "writer = SummaryWriter() # Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    train_loss = 0\n",
    "    for i, (X, y_actions, y_parameters) in enumerate(train_loader):  \n",
    "        # Move tensors to the configured device\n",
    "        X = X.to(device)\n",
    "        y_actions = y_actions.to(device)\n",
    "        y_parameters = y_parameters.to(device)\n",
    "        \n",
    "        N = X.shape[0] # num of data\n",
    "        \n",
    "        # Forward pass\n",
    "        output_actions, output_parameters_array = model(X)\n",
    "        loss_actions = criterion_actions(output_actions, y_actions) / N\n",
    "        \n",
    "        y_parameters = split_parameters(y_parameters)\n",
    "        loss_parameters = compute_parameter_loss(output_parameters_array, y_parameters, y_actions, criterion_parameters) / (2 * N)\n",
    "        \n",
    "        loss = loss_actions + loss_parameters\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    test_loss = get_test_loss(model, criterion_actions, criterion_parameters, test_loader) / num_test_data\n",
    "    \n",
    "    writer.add_scalar('loss/1:training_loss', train_loss, epoch + 1)\n",
    "    writer.add_scalar('loss/2:test_loss', test_loss, epoch + 1)\n",
    "    \n",
    "    if (epoch + 1) % SAVE_EVERY == 0:\n",
    "        filename = './models/%s_%d.model' % (NAME, epoch)\n",
    "        torch.save(model.state_dict(), filename)\n",
    "        print(\"File %s created\" % filename)\n",
    "    \n",
    "    print('Epoch [{}/{}], Loss: {:.4f}, Test Loss: {:.4f}'.format(epoch+1, NUM_EPOCHS, train_loss, test_loss))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_p36]",
   "language": "python",
   "name": "conda-env-pytorch_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
